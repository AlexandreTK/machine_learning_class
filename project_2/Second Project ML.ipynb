{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2748"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = pd.read_csv('amazon_cells_labelled.txt', sep=\"\\t\", usecols=[0], header=None)\n",
    "Y_1 = pd.read_csv('amazon_cells_labelled.txt', sep=\"\\t\", usecols=[1], header=None)\n",
    "\n",
    "X_2 = pd.read_csv('imdb_labelled.txt', sep=\"\\t\", usecols=[0], header=None)\n",
    "Y_2 = pd.read_csv('imdb_labelled.txt', sep=\"\\t\", usecols=[1], header=None)\n",
    "\n",
    "X_3 = pd.read_csv('yelp_labelled.txt', sep=\"\\t\", usecols=[0], header=None)\n",
    "Y_3 = pd.read_csv('yelp_labelled.txt', sep=\"\\t\", usecols=[1], header=None)\n",
    "\n",
    "\n",
    "X = np.concatenate((X_1.values[:,0], X_2.values[:,0]), axis=0)\n",
    "Y = np.concatenate((Y_1.values[:,0], Y_2.values[:,0]), axis=0)\n",
    "X = np.concatenate((X, X_3.values[:,0]), axis=0)\n",
    "Y = np.concatenate((Y, Y_3.values[:,0]), axis=0)\n",
    "#X = X_1.values[:,0]\n",
    "#Y = Y_1.values[:,0]\n",
    "\n",
    "len(Y)\n",
    "\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treating Sentences\n",
    "allSentences = []\n",
    "charsSplit = \"\\\\`*_{}[]()>#+-.!$,:&?\"\n",
    "charsRemove = \".,-_;\\\"\\'\"\n",
    "for x in X :\n",
    "    for c in charsSplit:\n",
    "        x = x.replace(c, ' '+ c +' ')\n",
    "    for c in charsRemove:\n",
    "        x = x.replace(c, '')\n",
    "    allSentences.append(x.lower() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allWords = []\n",
    "for x in allSentences :\n",
    "    allWords.extend(x.split(\" \"))\n",
    "\n",
    "\n",
    "allWords = list(set(allWords))\n",
    "allWords.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2748   2748   5372   4929\n"
     ]
    }
   ],
   "source": [
    "#len(Y)\n",
    "\n",
    "positiveCount = [0] * len(allWords)\n",
    "negativeCount = [0] * len(allWords)\n",
    "\n",
    "sentenceNumber = 0\n",
    "for sentenceNumber, sentence in enumerate(allSentences) :\n",
    "    for word in sentence.split(\" \"):\n",
    "        wordIndex = allWords.index(word)\n",
    "        if (Y[sentenceNumber] == 1):\n",
    "            positiveCount[wordIndex] = positiveCount[wordIndex] + 1\n",
    "        else:\n",
    "            negativeCount[wordIndex] = negativeCount[wordIndex] + 1\n",
    "            \n",
    "    #sentenceNumber = sentenceNumber + 1\n",
    "    \n",
    "allCount =  np.array(positiveCount) + np.array(negativeCount)\n",
    "probPositive = np.divide(positiveCount, allCount)\n",
    "\n",
    "#print(len(X), \" \", len(Y), \" \", len(probPositive), \" \", len(allWords))\n",
    "len(allWords)\n",
    "allWordsFiltered =  np.array(allWords)\n",
    "\n",
    "len(allWordsFiltered)\n",
    "index_to_remove = []\n",
    "for index, prob in enumerate(probPositive):\n",
    "    if not((prob <= 0.48) or (prob >= 0.52)):\n",
    "        #print(index , \"-- \" , prob, \"-- \" )\n",
    "        #allWordsFiltered = np.delete(allWordsFiltered, index)\n",
    "        index_to_remove.append(index)\n",
    "        a = 1\n",
    "\n",
    "allWordsFiltered = np.delete(allWordsFiltered, index_to_remove)\n",
    "\n",
    "print(len(X), \" \", len(Y), \" \", len(probPositive), \" \", len(allWordsFiltered))\n",
    "\n",
    "#print(allWords)     \n",
    "\n",
    "#print(probPositive)\n",
    "\n",
    "#probNegative = np.divide(negativeCount, allCount)\n",
    "#print(probNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2748"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords = np.array(allWordsFiltered).tolist()\n",
    "X = []\n",
    "for x in allSentences :\n",
    "    sentenceV = [0] * len(allWords)\n",
    "    words = x.split(\" \")\n",
    "    for w in words :\n",
    "        try:\n",
    "            index = allWords.index(w)\n",
    "            sentenceV[index] = 1 #sentenceV[index] + 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    X.append(sentenceV)\n",
    "\n",
    "len(allWords)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X[2][allWords.index('great')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 0.852974803574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_k = 10\n",
    "\n",
    "\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# clf = GaussianNB()\n",
    "\n",
    "\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# clf = BernoulliNB()\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB()\n",
    "\n",
    "\n",
    "# from sklearn.decomposition import KernelPCA\n",
    "# kpca = KernelPCA(n_components=300, kernel='linear')\n",
    "# X_KPCA = kpca.fit_transform(X)\n",
    "\n",
    "#print(len(X_KPCA))\n",
    "#print(len(X))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf1 = MultinomialNB()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf2 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# from sklearn import tree\n",
    "# clf2 = tree.DecisionTreeClassifier()\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf2 = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf3 = LogisticRegression(penalty='l2', C=1.0)\n",
    "# from sklearn import svm\n",
    "# clf3 = svm.SVC(kernel='linear', C=1.0, probability=True)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[3,2,2])\n",
    "\n",
    "accuracy = cross_val_score(eclf, X, Y, cv=cross_val_k, scoring='accuracy').mean()\n",
    "print('MultinomialNB', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Melhor resultado:\n",
    "\n",
    "- VotingClassifier\n",
    "\n",
    "MultinomialNB (peso 3)\n",
    "KNeighborsClassifier (peso 2)    -> 0.69429994326\n",
    "LogisticRegression (peso 2) penalty='l2'\n",
    "0.834031245492\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
